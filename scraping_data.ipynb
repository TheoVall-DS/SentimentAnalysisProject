{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapy \n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spyder(scrapy.Spider):\n",
    "    name = 'Spyder'\n",
    "\n",
    "    # Страницы с отзывами на все категории, связанные с мобильными телефонами\n",
    "    def start_requests(self):\n",
    "        urls_1 = ['https://otziv-otziv.ru/katalog/smartphones/?page=' + str(n) for n in range(1, 81)]\n",
    "        urls_2 = ['https://otziv-otziv.ru/katalog/phones/?page=' + str(n) for n in range(1, 26)]\n",
    "        urls_3 = ['https://otziv-otziv.ru/katalog/mobilnye-telefony/?page=' + str(n) for n in range(1, 709)]\n",
    "        urls = urls_1 + urls_2 + urls_3\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url = url, callback = self.parse_page)\n",
    "    \n",
    "    # Парсинг ссылок на модели\n",
    "    def parse_page(self, response):\n",
    "        model_links = response.css('div.content > a::attr(href)').extract()\n",
    "        model_links = list(map(lambda x: 'https://otziv-otziv.ru/' + x, model_links))\n",
    "        for model_link in model_links:\n",
    "            yield response.follow(url = model_link, callback = self.parse_model)\n",
    "    \n",
    "    # Парсинг страниц с отзывами для каждой модели\n",
    "    def parse_model(self, response):\n",
    "        last_child = int(response.css('ul.pagination > li:nth-last-of-type(3) > a::text').extract()[0])\n",
    "        review_page_links = [response.url + '?page=' + str(n) for n in range(1, last_child + 1)]\n",
    "        for review_page_link in review_page_links:\n",
    "            yield response.follow(url = review_page_link, callback = self.parse_comments)\n",
    "            \n",
    "    # Парсинг самих отзывов\n",
    "    def parse_comments(self, response):\n",
    "        try:\n",
    "            # Блоки div с комментариями\n",
    "            req = requests.get(response.url)\n",
    "            parser = bs4.BeautifulSoup(req.text, 'lxml')\n",
    "            div_blocks = parser.findAll('div', attrs={'class':'container-reviews collapsible collapsed'})\n",
    "            \n",
    "            # Парсинг блоков, где есть комментарий\n",
    "            for info in div_blocks:\n",
    "                comment_ind = info.text.find('Комментарий:')\n",
    "                if comment_ind == -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    comment = info.text[comment_ind+12:].replace('\\n', ' ').strip()\n",
    "                    rating = int(info.find('div', attrs={'class':'stars-container'}).attrs['title'][-1])\n",
    "                    reviews.append((comment, rating))\n",
    "                    \n",
    "        except requests.exceptions.ConnectionError:\n",
    "            reviews.append(('ошибка подключения', -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск краулера !!!Осторожно, занял 6.5 часов!!!\n",
    "reviews = []\n",
    "process = CrawlerProcess()\n",
    "process.crawl(Spyder)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение в csv-файл\n",
    "data = pd.DataFrame(reviews, columns = ['Review', 'Rating']).to_csv('data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
